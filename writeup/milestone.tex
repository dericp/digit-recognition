\documentclass{article} % For LaTeX2e
\usepackage{nips13submit_e,times}
\usepackage{hyperref}
\usepackage{url}
%\documentstyle[nips13submit_09,times,art10]{article} % For LaTeX 2.09


\title{Machine Learning Milestone}


\author{
Deric Pang \\
\texttt{dericp@cs.washington.edu} \\
\And
Saidutt Nimmagadda \\
\texttt{nimmas@cs.washington.edu} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle

\begin{abstract}
Our project investigates the task of recognizing handwritten digits. Our initial
project proposal involved reading three papers [1]-[3] and determining which
techniques to use to achieve our task.
\end{abstract}

\section{Project Description}

\subsection{yolo}
swag swag swag

\section{Progress}
We have implemented a classifier using $k$-nearest neighbors regression. 
We found the k point(s) with the smallest Euclidean distance(s). Given runtime constraints,
we ran the algorithm on a fraction of the dataset (1000 rows) with validation blocks of
size 200 rows. For each row of the validation set, we found the $k$ nearest neighbors. Then, for
each of these neighbors' classifications, amongst the $k$ nearest neighbors, we find the classification
with the lowest average distance. This classification will be our prediction $\hat{y}$ for the given $x_i$.

We then compare our $\hat{y}$ to the true classification. The number of incorrect predictions divided by
the number of total predictions is validation error. As we iterate over our validation blocks,
we try different values of k (1, 5, 10, 50, and 100), and then graph the corresponding validation errors.

\subsubsection*{References}

\small{
  [1] LeCun, Yann, et al. "Comparison of learning algorithms for handwritten
  digit recognition." International conference on artificial neural networks.
  Vol. 60. 1995.	

  [2] Maji, Subhransu, and Jitendra Malik. "Fast and accurate digit
  classification." EECS Department, University of California,
  Berkeley, Tech. Rep. UCB/EECS-2009-159 (2009).

  [3] Sundaresan, Vishnu, and Jasper Lin. "Recognizing Handwritten Digits and
  Characters." (1998).
}

\end{document}
