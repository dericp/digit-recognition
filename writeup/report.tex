\documentclass{article} % For LaTeX2e
\usepackage{nips13submit_e,times}
\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}
\graphicspath{ {images/} }
%\documentstyle[nips13submit_09,times,art10]{article} % For LaTeX 2.09


\title{An Investigation of Classification Techniques For Handwritten Digit Recognition}


\author{
Deric Pang \\
\texttt{dericp@cs.washington.edu} \\
\And
Saidutt Nimmagadda \\
\texttt{nimmas@cs.washington.edu} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}

\maketitle

\begin{abstract}
  TODO
\end{abstract}

\section{Introduction}
TODO

\section{Project Description}
\subsection{Goal}

Our goal for this project is quite simple---we want to
take pixel data from images of hand-drawn digits
and classify them as a number from 0 to 9.

\subsection{Data}

The data for our project was taken from the MNIST dataset. As written on a
Kaggle competition using the MNIST dataset, ``The MNIST
('Modified National Institute of Standards and Technology') dataset
is a classic within the Machine Learning community that has been extensively
studied. More detail about the dataset, including Machine Learning algorithms
that have been tried on it and their levels of success, can be found at
\href{http://yann.lecun.com/exdb/mnist/index.html}{http://yann.lecun.com/exdb/mnist/index.html}.''

Each handwritten digit is vectorized. Each vector is composed of a label which
represents the label classification (i.e. numbers from 0 to 9) and 783 pixel
features of integer values between 0 and 255. Since all
of the data is already normalized and centered, we did not need to take those
steps ourselves to start building models against. The training data set
consists of 60,000 data points, while the test set consists of 10,000 data
points.

The specific flavor of the MNIST dataset that we used came from
\href{https://pjreddie.com/projects/mnist-in-csv/}{https://pjreddie.com/projects/mnist-in-csv/}
where the data is formated as CSV files.

\section{First Considerations}
\subsection{Machine Learning Techniques}
TODO

\subsection{Related Work}
Before we began implementing any classifiers, we wanted to investigate what
material already existed in the domain of digit recognition. We discovered
that digit recognition, especially on the MNIST database, is an extremely well
studied problem. As such, we had no trouble finding a plethora of detailed
papers.

Going into the project, we had intuition that the most accurate classifier we
could build was a convolutional neural network. This was confirmed in most of
the related work [1 - 3].
However, we wanted to determine which techniques would be the most insightful,
interesting, and performant to implement for our project even though the
readings pointed out a clear state-of-the-art.

We saw from the
conclusions of Lecun [1] that a k-Nearest Neighbors classifier would not
only pose serious scaleability difficulties when it came to runtime and memory
usage, but it would also be a comparatively unreliable classifier. We decided
that it would be interesting to see just how difficult it would be to deal with
the runtime and what kind of accuracy we could achieve with limited
computation resources.

We also saw that according to Maji [2], ``with improved features a low
complexity classifier, in particular
an additive-kernel SVM, can achieve state of the art performance.'' This
inspired us to implement a support vector machine as a lightweight, high
accuracy classifier.

%Our findings from the milestone portion of the project confirms this, with our implementation
%of k-NN taking a good amount of time (roughly 5 minutes) to run over less than
%10 percent of the total dataset. In addition, we only achieved classification
%errors of roughly 10 
%to 20 percent. When we implement a convolutional neural network, like LeCun did
%in his paper, we expect a decrease in runtime and memory usage (which
%would promote scaleability), as well as a large decrease in classification error.

\section{Approach}

\subsection{Baselines}
We used scikit-learn [6] to implement baselines for the $k$-NN classifier and the SVM.
Even though scikit-learn is presumably optimized very well, these classifiers took a very
long time to train and evaluate. As a result, we tuned hyperparameters with only
17\% of our training data. Once we settled upon optimal hyper
parameters, we trained the scikit-learn $k$-NN and SVM on 25\% of the training set and evaluated
them on the entirety of the test set.

%After implementing the baselines, we implemented the algorithms themselves.
%For each high level algorithm, we implemented different refinements and ran
%cross-validation in order to get a diverse array of data for a diverse array of
%techniques. We kept a high scope by having multiple algorithms, and we kept a
%high depth by tinkering with each algorithm. Finally, we used TensorFlow to
%implement a convolutional neural network. We knew from the readings we’d read
%that a CNN would perform optimally, and we wanted to have our own optimal
%baseline to compare our results to.

\subsection{Evaluation}
To tune hyperparameters, we used cross-validation with random 80-20 splits. We
consistently report the validation errors from the cross-validation and the test
error on the MNIST test set.

\subsection{$k$-Nearest Neighbors ($k$-NN)}
\subsubsection{Scikit-learn $k$-NN}
To baseline our $k$-NN classifier, we used
scikit-learn's $k$-NN implementation.
Scikit-learn's $k$-NN can utilize different approaches like brute-force,
a K-D tree, and a Ball tree.
The K-D tree and Ball tree trade precision for efficiency by utilizing heuristics to
prune which points are considered when evaluating the nearest neighbors.
Scikit-learn
decides which algorithm to use based on the number of samples $N$, the
dimensionality of the data $D$, the
structure of the data (e.g. sparsity, intrinsic dimensionality), the number
of neighbors $k$ requested for a query point, and the number of query points.

After tuning $k$ using cross-validation, we found that scikit-learn prefers to
use a K-D tree. Running cross-validation over a set of $k$ values between
1 and 625, we found that $k = 1$ minimized our validation error. The results of
this cross-validation can be seen in figure \ref{fig:sklearn-knn-k-cv}.

\begin{figure}[h]
\includegraphics[width=\textwidth]{sklearn-knn-k-cv.png}
\caption{cross validation of scikit-learn's $k$-NN over varying $k$ values}
\label{fig:sklearn-knn-k-cv}
\end{figure}

\subsubsection{$k$-NN Regression}
We have implemented a $k$-NN classifier using
$k$-NN regression. We used a brute force algorithm that scans every point
in the training set to find the k neighbors with the lowest Euclidean distances from 
the query point. Then, amongst those k neighbors, we found the classification with the lowest
average Euclidean distance from the query point. That classification was assigned to the
query point.

We found the runtime of $k$-NN when using the entire training set of 60,000
images to be intractable. Given runtime constraints,
we used 10\% of the training set in our $k$-NN regression.
We found that with $k = 1$, our $k$-NN classifier obtained the lowest validation
error. This was consistent with the result of cross-validation on
scikit-learn's
$k$-NN classifier. 
We initially hoped that as $k$
increased, our classification error would decrease. However, without a
proper kernel to weigh the data points, we decided that it was possible for
larger values of $k$ to produce inaccurate classifications.
Results of cross-validation over varying $C$ values can be seen in figure \ref{fig:knn-c-cv}.

\begin{figure}[h]
\includegraphics[width=\textwidth]{knn-c-cv.png}
\caption{cross validation of $k$-NN over varying $k$ values}
\label{fig:knn-c-cv}
\end{figure}

\subsubsection{Kernelized $k$-NN}
We implemented a Gaussian kernel and classified query points
based off of the Nadaraya Watson Kernel Weighted Average. Instead of finding
the k nearest neighbors to classify a query point, we used this Kernelized
Regression to calculate the classification for each query point.

TODO include kernel formulation here

Since we didn’t have to just find the k nearest neighbors, but instead
iterated through every point and kernelized its distance as a weight to
its classification, we had to tune our bandwidth value $\lambda$ rather than a k.
As a result of overflow and underflow errors, we could only test a range
of bandwidths from $10^4$ to $10^6$. 


\begin{figure}[h]
\includegraphics[width=\textwidth]{knn-kernel-bandwidth-cv.png}
\caption{cross validation of kernelized $k$-NN over varying bandwidth values}
\label{fig:knn-kernel-bandwidth-cv}
\end{figure}

Running cross validation on 1/10th of our training set, we found that a
bandwidth of 104 not only avoided overflow errors, it also minimized validation error.

\subsection{Support Vector Machine (SVM)}
\subsubsection{Scikit-learn SVM}
We then tackled Support Vector Machines. For baselining,
we used scikit-learns LinearSVC and SVC functionality. The
former trains a Support Vector Machine until convergence with
a Linear kernel, and the latter with a Radial Basis function kernel. 

To baseline our SVM, we trained two SVMs using scikit-learn. The first SVM was a
linear SVM, and the second used a Radia Basis function kernel.

\begin{figure}[h]
\includegraphics[width=\textwidth]{sklearn-svm-c-cv.png}
\end{figure}

\begin{figure}[h]
\includegraphics[width=\textwidth]{sklearn-svm-kernel-c-cv.png}
\end{figure}

Running cross-validation for each C value over a small subset of
the training set (10000 rows), we found that C values of 1 and 100
minimized validation error in the Linear and RBF SVMs respectively.
This was surprising to us, especially the former C-value, and we
suspected after some tinkering around that the differences in
validation error can be ascribed to differences in the validation
blocks’ data rather than differences in C value. Nonetheless, we
used those respective C-values for creating our model against the
the training data and running it against the test data. 


\subsection{CNN}
TODO

\section{Results}

\subsubsection*{References}

\small{
  [1] LeCun, Yann, et al. "Comparison of learning algorithms for handwritten
  digit recognition." International conference on artificial neural networks.
  Vol. 60. 1995.	

  [2] Maji, Subhransu, and Jitendra Malik. "Fast and accurate digit
  classification." EECS Department, University of California,
  Berkeley, Tech. Rep. UCB/EECS-2009-159 (2009).

  [3] Sundaresan, Vishnu, and Jasper Lin. "Recognizing Handwritten Digits and
  Characters." (1998).

  [4] Shalev-Shwartz, Shai, Yoram Singer, and Nathan Srebro. "Pegasos: Primal
  estimated sub-gradient solver for svm." Proceedings of the 24th international
  conference on Machine learning. ACM, 2007.

  [5] Rahimi, Ali, and Benjamin Recht. "Random Features for Large-Scale Kernel
  Machines." NIPS. Vol. 3. No. 4. 2007.

  [6] Pedregosa, Fabian, et al. "Scikit-learn: Machine learning in Python."
  Journal of Machine Learning Research 12.Oct (2011): 2825-2830.
}

\end{document}
